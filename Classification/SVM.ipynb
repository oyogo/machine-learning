{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Most sectors of the economy are embracing data science in their practises and consequently seeing improved performance and efficiency and the education sector is not left out. \n",
    "With such a huge amount of data being generated from schools in particular, we can make use of data science concepts to, for example, improve student performance, learning experience and to foster data-driven decision making in the managerial ranks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief on Support Vector Machines\n",
    "  \n",
    "Support Vector Machine is a set of supervised machine learning algorithms used to solve classification and regression problems.   \n",
    "\n",
    "SVM's can be further categorized into two types:  \n",
    "* SVR (Support vector regression) : for solving regression problems. \n",
    "* SVC (Support vector classification): for solving classification problems.  \n",
    "\n",
    "SVC Performs both linear and non-linear classification: \n",
    "Linear: \n",
    "\n",
    "Say you have labelled data with a feature which has two groupings (male and female, spam not not-spam), SVMs works in such a way that a line (mostly referred to as a hyperplane) is sought which separates the two distinct labels from each other. The optimal hyperplane would be one whereby the closest label from both group A and group B is as far as possible from the hyperplane (decision boundary) so that the groups are as distinct as possible.   \n",
    "Its called a decision boundary seeing that its used to decide whether a point falls in group A or group B.  \n",
    "Now, that works only for a case where the two groups are linearly separable. \n",
    "\n",
    "There are cases where the groupings are not linearly separable. \n",
    "\n",
    "Enter Non-linear classification: \n",
    "The non-linear classification is performed using the kernel function. \n",
    "When the dataset is separable by nonlinear boundary, certain kernels are implemented in the SVM to appropriately transform the feature space. \n",
    "\n",
    "A kernel is a function that transforms the data into a higher dimensional feature space where data is separable.  \n",
    "\n",
    "Kernel functions:  \n",
    "* Linear\n",
    "* Polynomial \n",
    "* Gaussian Radial Basis Function  \n",
    "* Sigmoid  \n",
    "\n",
    "The radial basis function kernel is mostly used for non-linear problems. \n",
    "\n",
    "SVM's are mostly used in text classification problems.  \n",
    "One of the gains to using SVM is that it helps to find complex relationships in your data without much transformations.   \n",
    "Works well in cases where the features are more than the samples. \n",
    "Its memory efficient. (uses a subset of the training points in the decision function).  \n",
    "\n",
    "Cons of SVM's  : \n",
    "SVM's don't give probability estimates. You have to calculate.  \n",
    "Works best on small sample datasets.  \n",
    "Can be memory consuming especially when processing huge volume of data.  \n",
    "\n",
    "\n",
    "What's covered in this article: \n",
    "* Data import  \n",
    "* Inspecting the data.  \n",
    "* Data munging and preprocessing.  \n",
    "* Data partitioning  \n",
    "* Modelling.  \n",
    "* Predicting.  \n",
    "* Model evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/clinton/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/clinton/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/clinton/.vscode/extensions/ms-toolsai.jupyter-2022.7.1102252217/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 168, in _start_notebook\n",
      "\u001b[1;31m    app.launch_new_instance()\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/jupyter_core/application.py\", line 269, in launch_instance\n",
      "\u001b[1;31m    return super().launch_instance(argv=argv, **kwargs)\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n",
      "\u001b[1;31m    app.start()\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/notebook/notebookapp.py\", line 2320, in start\n",
      "\u001b[1;31m    success = self._bind_http_server()\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/notebook/notebookapp.py\", line 1795, in _bind_http_server\n",
      "\u001b[1;31m    return self._bind_http_server_unix() if self.sock else self._bind_http_server_tcp()\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/notebook/notebookapp.py\", line 1821, in _bind_http_server_tcp\n",
      "\u001b[1;31m    self.http_server.listen(port, self.ip)\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/tornado/tcpserver.py\", line 183, in listen\n",
      "\u001b[1;31m    sockets = bind_sockets(\n",
      "\u001b[1;31m  File \"/opt/homebrew/lib/python3.10/site-packages/tornado/netutil.py\", line 162, in bind_sockets\n",
      "\u001b[1;31m    sock.bind(sockaddr)\n",
      "\u001b[1;31mOSError: [Errno 49] Can't assign requested address\n",
      "\u001b[1;31m\n",
      "\u001b[1;31m/opt/homebrew/lib/python3.10/site-packages/traitlets/traitlets.py:2412: FutureWarning: Supporting extra quotes around strings is deprecated in traitlets 5.0. You can use '/Users/clinton/Documents/zangu_projects/machine-learning/Classification' instead of '\"/Users/clinton/Documents/zangu_projects/machine-learning/Classification\"' if you require traitlets >=5.\n",
      "\u001b[1;31m  warn(\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/clinton/Documents/zangu_projects/machine-learning/Classification\" --config=/var/folders/3m/pnwq5p0s7370xf6r_3n3tx840000gp/T/b1a1d094-19d9-4bb8-bf4d-7d670c1a038e/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementInclude import include\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "svc_data = pd.read_csv(\"../data/student_performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inspection\n",
    "svc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "## Encode the categorical variables to numeric\n",
    "\n",
    "svc_data1 = svc_data.replace({'address':{'R':0,'U':1},\n",
    "                            'famsize':{'LE3':0,'GT3':1},\n",
    "                            'Pstatus':{'T':0,'A':1},\n",
    "                            'Mjob':{'teacher':0,'at_home':1,'services':2,'other':3,'health':4},\n",
    "                            'Fjob':{'teacher':0,'at_home':1,'services':2,'other':3,'health':4},\n",
    "                            'guardian':{'mother':0,'father':1,'other':2},\n",
    "                            'schoolsup':{'yes':1,'no':0},\n",
    "                            'famsup':{'yes':1,'no':0},\n",
    "                            'paid':{'no':0,'yes':1},\n",
    "                            'activities':{'no':0,'yes':1},\n",
    "                            'nursery':{'no':0,'yes':1},\n",
    "                            'higher':{'yes':1,'no':0},\n",
    "                            'internet':{'no':0,'yes':1},\n",
    "                            'romantic':{'no':0,'yes':1},\n",
    "                            'sex':{'F':0,'M':1}\n",
    "                            }, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Seeing that we want to model a classification model, we'll categorize the marks into two groups, <10 will be a fail and >10 a pass. \n",
    " To achieve that we'll use a conditional replace with the help of numpy function np.where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_data['G3'] = np.where(svc_data['G3']>=10,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns are not needful as such we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_data.drop(['G1','reason','school'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## response variable\n",
    "y = svc_data['G3']\n",
    "## predictor variables\n",
    "X = svc_data.drop('G3',axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Separate categorical columns from numeric ones. Further separate categorical columns into those \n",
    "needing to be oneHot encoded and those that need to be ordinalEncoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = x_train.select_dtypes(exclude=['object']).columns.tolist() # extract numeric columns\n",
    "cat_cols = x_train.select_dtypes(include=['object']).columns.tolist() # extract categorical columns \n",
    "ord_cols = ['Medu','Fedu','traveltime','studytime','famrel','freetime','goout','Dalc','Walc','health'] # categorical columns with order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll drop ordinal columns from the numeric columns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ordinal columns from the numeric columns list\n",
    "num_cols = [value for value in num_cols if value not in ord_cols]\n",
    "num_cols = [value for value in num_cols if value != \"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='constant',fill_value='N/A'),\n",
    "    OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for ordinal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_pipe = make_pipeline(\n",
    "    OrdinalEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('num',num_pipe,num_cols),\n",
    "    ('cat',cat_pipe,cat_cols),\n",
    "    ('ord',ord_pipe,ord_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = make_pipeline(full_pipeline, SVC(kernel='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the accuracy_score method from sklearn metrics module to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mlearning_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c8c4948a6948d162a0b3007104f2337aad2bc004b112fcee2258142f777f9b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
